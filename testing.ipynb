{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMH/BcAO6W7r/1EkdiU/5AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKawsar/game_python/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o5TxbMNlcgb"
      },
      "outputs": [],
      "source": [
        "# to remove unnecessary warnings\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# from R_configuration import parameters_DT\n",
        "from ml_scripts.helpers.console_log import send_console_log\n",
        "\n",
        "from ml_scripts.regression.AB_regressor import adaboost_regressor\n",
        "from ml_scripts.regression.DT_regressor import decision_tree_regressor\n",
        "from ml_scripts.regression.EN_regressor import elastic_net_regressor\n",
        "from ml_scripts.regression.R_function_lib_ML import cv_result\n",
        "from ml_scripts.regression.R_function_lib_validation import test_error\n",
        "from ml_scripts.regression.GB_regressor import gradient_boosting_regressor\n",
        "from ml_scripts.regression.L_regressor import linear_regressor\n",
        "from ml_scripts.regression.Lasso_regressor import lasso_regressor\n",
        "from ml_scripts.regression.MLP_regressor import multi_layer_perceptron_regressor\n",
        "from ml_scripts.regression.RF_regressor import random_forest_regressor\n",
        "from ml_scripts.regression.Ridge_regressor import ridge_regressor\n",
        "from ml_scripts.regression.SV_regressor import support_vector_regressor\n",
        "from ml_scripts.regression.XGB_regressor import x_gradient_boosting_regressor\n",
        "from ml_scripts.common.model_insight_functions import (feature_importance,\n",
        "                                                       permutation_feature_importance,\n",
        "                                                       linear_model_feature_importance)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class MlAlgo:\n",
        "    def __init__(self, experiment_id):\n",
        "        self.experiment_id = experiment_id\n",
        "        # self.parameters_DT = parameters_DT\n",
        "\n",
        "    def run_DT(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Decision Tree Regressor with \" +\n",
        "                         str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_dt = decision_tree_regressor(x_train,\n",
        "                                           y_train,\n",
        "                                           parameter[\"criterion\"],\n",
        "                                           parameter[\"max_features\"],\n",
        "                                           parameter[\"max_depth\"],\n",
        "                                           parameter[\"min_samples_leaf\"],\n",
        "                                           parameter[\"min_samples_split\"],\n",
        "                                           kpi,\n",
        "                                           cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_dt = cv_result(model_dt)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_dt = np.round(model_dt.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_dt['test_score'] = np.round(test_error(y_test,\n",
        "                                                         y_pred_dt,\n",
        "                                                         kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_dt['item'] = uni_val\n",
        "        cv_result_dt['model'] = 'Decision Tree'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = feature_importance(model_dt, x_train, 'DT', uni_val)\n",
        "\n",
        "        # visualize the tree diagram for the model\n",
        "        # tree_viz(x_train, model_dt.best_estimator_, uni_val+'_tree_DT.dot', uni_val+'_tree_DT.png')\n",
        "\n",
        "        return y_pred_dt, cv_result_dt.head(1), df_fi, model_dt.best_params_\n",
        "\n",
        "    def run_RF(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Random Forest Regressor with \"\n",
        "                         + str(cv) + \"-fold cross-validation ...\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_rf = random_forest_regressor(x_train,\n",
        "                                           y_train,\n",
        "                                           parameter[\"criterion\"],\n",
        "                                           parameter[\"n_estimators\"],\n",
        "                                           parameter[\"bootstrap\"],\n",
        "                                           parameter[\"max_features\"],\n",
        "                                           parameter[\"max_depth\"],\n",
        "                                           kpi,\n",
        "                                           cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_rf = cv_result(model_rf)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_rf = np.round(model_rf.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_rf['test_score'] = np.round(test_error(y_test, y_pred_rf, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_rf['item'] = uni_val\n",
        "        cv_result_rf['model'] = 'Random Forest'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = feature_importance(model_rf, x_train, 'RF', uni_val)\n",
        "\n",
        "        # visualize the tree diagram for the model\n",
        "        # tree_viz(x_train, model_rf.best_estimator_.estimators_[0], uni_val+'_tree_RF.dot', uni_val+'_tree_RF.png')\n",
        "\n",
        "        return y_pred_rf, cv_result_rf.head(1), df_fi, model_rf.best_params_\n",
        "\n",
        "    def run_AB(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating AdaBoost Regressor with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_ab = adaboost_regressor(x_train,\n",
        "                                      y_train,\n",
        "                                      parameter[\"base_estimator\"],\n",
        "                                      parameter[\"n_estimators\"],\n",
        "                                      parameter[\"learning_rate\"],\n",
        "                                      parameter[\"loss\"],\n",
        "                                      kpi,\n",
        "                                      cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_ab = cv_result(model_ab)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_ab = np.round(model_ab.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_ab['test_score'] = np.round(test_error(y_test, y_pred_ab, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_ab['item'] = uni_val\n",
        "        cv_result_ab['model'] = 'AdaBoost'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = feature_importance(model_ab, x_train, 'AB', uni_val)\n",
        "\n",
        "        return y_pred_ab, cv_result_ab.head(1), df_fi, model_ab.best_params_\n",
        "\n",
        "    def run_GB(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Gradient Boosting Regressor with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_gb = gradient_boosting_regressor(x_train,\n",
        "                                               y_train,\n",
        "                                               parameter[\"criterion\"],\n",
        "                                               parameter[\"max_depth\"],\n",
        "                                               parameter[\"n_estimators\"],\n",
        "                                               parameter[\"learning_rate\"],\n",
        "                                               kpi,\n",
        "                                               cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_gb = cv_result(model_gb)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_gb = np.round(model_gb.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_gb['test_score'] = np.round(test_error(y_test, y_pred_gb, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_gb['item'] = uni_val\n",
        "        cv_result_gb['model'] = 'Gradient Boosting'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = feature_importance(model_gb, x_train, 'GB', uni_val)\n",
        "\n",
        "        # visualize the tree diagram for the model\n",
        "        # tree_viz(x_train, model_gb.best_estimator_.estimators_[0, 0], uni_val+'_tree_GB.dot', uni_val+'_tree_GB.png')\n",
        "\n",
        "        return y_pred_gb, cv_result_gb.head(1), df_fi, model_gb.best_params_\n",
        "\n",
        "    def run_MLP(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Artificial Neural Network with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        # model_mlp = multi_layer_perceptron_regressor(x_train, y_train, [0.1], ['tanh'], ['adam'], [16], [300],\n",
        "        #                                              [(50, 50), (100,), (150,), (200,), (250,), (300,)], kpi, 5)\n",
        "        model_mlp = multi_layer_perceptron_regressor(x_train,\n",
        "                                                     y_train,\n",
        "                                                     parameter[\"activation\"],\n",
        "                                                     parameter[\"solver\"],\n",
        "                                                     parameter[\"learning_rate_init\"],\n",
        "                                                     parameter[\"max_iter\"],\n",
        "                                                     parameter[\"hidden_layer_sizes\"],\n",
        "                                                     kpi,\n",
        "                                                     cv)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_mlp = cv_result(model_mlp)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_mlp = np.round(model_mlp.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_mlp['test_score'] = np.round(test_error(y_test, y_pred_mlp, kpi), 2)\n",
        "\n",
        "        # create a new column 'item' to save the unique value\n",
        "        cv_result_mlp['item'] = uni_val\n",
        "        cv_result_mlp['model'] = 'Neural Network'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = permutation_feature_importance(model_mlp, x_train, y_train, kpi, 'MLP', uni_val)\n",
        "\n",
        "        return y_pred_mlp, cv_result_mlp.head(1), df_fi, model_mlp.best_params_\n",
        "\n",
        "    def run_XGB(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Extreme Gradient Boosting Regressor with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "        for col in x_train.columns:\n",
        "            if x_train[col].dtype.name == 'category':\n",
        "                x_train[col] = x_train[col].astype('int')\n",
        "                x_test[col] = x_test[col].astype('int')\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_xgb = x_gradient_boosting_regressor(x_train,\n",
        "                                                  y_train,\n",
        "                                                  parameter[\"max_depth\"],\n",
        "                                                  parameter[\"n_estimators\"],\n",
        "                                                  parameter[\"learning_rate\"],\n",
        "                                                  kpi,\n",
        "                                                  cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_xgb = cv_result(model_xgb)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_xgb = np.round(model_xgb.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_xgb['test_score'] = np.round(test_error(y_test, y_pred_xgb, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_xgb['item'] = uni_val\n",
        "        cv_result_xgb['model'] = 'XGB'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = feature_importance(model_xgb, x_train, \"XGB\", uni_val)\n",
        "\n",
        "        # # tree diagram for XGB\n",
        "        # plot_tree(model_xgb.best_estimator_, num_trees=1, rankdir='LR')\n",
        "        # # save the tree diagram\n",
        "        # plt.savefig(tree_plot_filepath + \"tree_XGB_\" + uni_val + '.png', bbox_inches='tight')\n",
        "\n",
        "        return y_pred_xgb, cv_result_xgb.head(1), df_fi, model_xgb.best_params_\n",
        "\n",
        "    def run_LR(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Linear regression with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_lr = linear_regressor(x_train,\n",
        "                                    y_train,\n",
        "                                    parameter[\"\"],\n",
        "                                    kpi,\n",
        "                                    cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_lr = cv_result(model_lr)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_lr = np.round(model_lr.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_lr['test_score'] = np.round(test_error(y_test, y_pred_lr, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_lr['item'] = uni_val\n",
        "        cv_result_lr['model'] = 'Linear regression'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        # df_fi = permutation_feature_importance(model_lr, x_train, y_train, kpi, \"LR\", uni_val)\n",
        "        df_fi = linear_model_feature_importance(model_lr, x_train, \"LR\", uni_val)\n",
        "\n",
        "        return y_pred_lr, cv_result_lr.head(1), df_fi, model_lr.best_params_\n",
        "\n",
        "    def run_Ri(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Ridge regression with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_ri = ridge_regressor(x_train,\n",
        "                                   y_train,\n",
        "                                   parameter[\"alpha\"],\n",
        "                                   parameter[\"fit_intercept\"],\n",
        "                                   kpi,\n",
        "                                   cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_ri = cv_result(model_ri)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_ri = np.round(model_ri.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_ri['test_score'] = np.round(test_error(y_test, y_pred_ri, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_ri['item'] = uni_val\n",
        "        cv_result_ri['model'] = 'Ridge regression'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        # df_fi = permutation_feature_importance(model_ri, x_train, y_train, kpi, \"Ri\", uni_val)\n",
        "        df_fi = linear_model_feature_importance(model_ri, x_train, \"Ri\", uni_val)\n",
        "\n",
        "        return y_pred_ri, cv_result_ri.head(1), df_fi, model_ri.best_params_\n",
        "\n",
        "    def run_La(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Lasso regression with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_la = lasso_regressor(x_train,\n",
        "                                   y_train,\n",
        "                                   parameter[\"alpha\"],\n",
        "                                   parameter[\"fit_intercept\"],\n",
        "                                   kpi,\n",
        "                                   cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_la = cv_result(model_la)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_la = np.round(model_la.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_la['test_score'] = np.round(\n",
        "            test_error(y_test, y_pred_la, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_la['item'] = uni_val\n",
        "        cv_result_la['model'] = 'Lasso regression'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        # df_fi = permutation_feature_importance(model_la, x_train, y_train, kpi, \"La\", uni_val)\n",
        "        df_fi = linear_model_feature_importance(model_la, x_train, \"La\", uni_val)\n",
        "\n",
        "        return y_pred_la, cv_result_la.head(1), df_fi, model_la.best_params_\n",
        "\n",
        "    def run_EN(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating ElasticNet regression with \"\n",
        "                         + str(cv) + \"-fold cross-validation …\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_en = elastic_net_regressor(x_train,\n",
        "                                         y_train,\n",
        "                                         parameter[\"alpha\"],\n",
        "                                         parameter[\"l1_ratio\"],\n",
        "                                         parameter[\"fit_intercept\"],\n",
        "                                         kpi,\n",
        "                                         cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_en = cv_result(model_en)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_en = np.round(model_en.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_en['test_score'] = np.round(test_error(y_test, y_pred_en, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_en['item'] = uni_val\n",
        "        cv_result_en['model'] = 'ElasticNet'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = linear_model_feature_importance(model_en, x_train, \"EN\", uni_val)\n",
        "        # df_fi = permutation_feature_importance(model_en, x_train, y_train, kpi, \"EN\", uni_val)\n",
        "\n",
        "        return y_pred_en, cv_result_en.head(1), df_fi, model_en.best_params_\n",
        "\n",
        "    def run_SV(self, x_train, y_train, kpi, uni_val, x_test, y_test, cv, parameter):\n",
        "\n",
        "        send_console_log(self.experiment_id,\n",
        "                         \"$ Training and validating Support Vector Regressor with \"\n",
        "                         + str(cv) + \"-fold cross-validation ...\")\n",
        "\n",
        "        # Grid search hyperparameter tuning\n",
        "        model_sv = support_vector_regressor(x_train,\n",
        "                                            y_train,\n",
        "                                            parameter[\"kernel\"],\n",
        "                                            parameter[\"c\"],\n",
        "                                            kpi,\n",
        "                                            cv)\n",
        "\n",
        "        # create a dataframe to hold the cross-validation results with the grid search\n",
        "        cv_result_sv = cv_result(model_sv)\n",
        "\n",
        "        # prediction on the test data\n",
        "        y_pred_sv = np.round(model_sv.predict(x_test), 2)\n",
        "\n",
        "        # calculate the error in test set\n",
        "        cv_result_sv['test_score'] = np.round(test_error(y_test, y_pred_sv, kpi), 2)\n",
        "\n",
        "        # determine the cross-validation results\n",
        "        cv_result_sv['item'] = uni_val\n",
        "        cv_result_sv['model'] = 'Support Vector'\n",
        "\n",
        "        # find feature importance of the model\n",
        "        df_fi = permutation_feature_importance(model_sv, x_train, y_train, kpi, \"SV\", uni_val)\n",
        "\n",
        "        return y_pred_sv, cv_result_sv.head(1), df_fi, model_sv.best_params_\n"
      ]
    }
  ]
}